{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"movie_review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_id</th>\n",
       "      <th>cv_tag</th>\n",
       "      <th>html_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>0</td>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>1</td>\n",
       "      <td>for starters , it was created by alan moore ( ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>2</td>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>3</td>\n",
       "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>4</td>\n",
       "      <td>in other words , don't dismiss this film becau...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold_id cv_tag  html_id  sent_id  \\\n",
       "0        0  cv000    29590        0   \n",
       "1        0  cv000    29590        1   \n",
       "2        0  cv000    29590        2   \n",
       "3        0  cv000    29590        3   \n",
       "4        0  cv000    29590        4   \n",
       "\n",
       "                                                text  tag  \n",
       "0  films adapted from comic books have had plenty...  pos  \n",
       "1  for starters , it was created by alan moore ( ...  pos  \n",
       "2  to say moore and campbell thoroughly researche...  pos  \n",
       "3  the book ( or \" graphic novel , \" if you will ...  pos  \n",
       "4  in other words , don't dismiss this film becau...  pos  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"fold_id\",\"cv_tag\",\"html_id\",\"sent_id\"],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for starters , it was created by alan moore ( ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in other words , don't dismiss this film becau...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  tag\n",
       "0  films adapted from comic books have had plenty...  pos\n",
       "1  for starters , it was created by alan moore ( ...  pos\n",
       "2  to say moore and campbell thoroughly researche...  pos\n",
       "3  the book ( or \" graphic novel , \" if you will ...  pos\n",
       "4  in other words , don't dismiss this film becau...  pos"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pos', 'neg'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tag\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tag\"] = df[\"tag\"].map({\"pos\":1,\"neg\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for starters , it was created by alan moore ( ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in other words , don't dismiss this film becau...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  tag\n",
       "0  films adapted from comic books have had plenty...    1\n",
       "1  for starters , it was created by alan moore ( ...    1\n",
       "2  to say moore and campbell thoroughly researche...    1\n",
       "3  the book ( or \" graphic novel , \" if you will ...    1\n",
       "4  in other words , don't dismiss this film becau...    1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64720, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df[\"text\"].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(message):\n",
    "    rm_punctuation = \"\".join([text for text in message if text not in [\"!\",\".\",\"$\",\"#\",\"(\",\")\",\"{\",\"}\",\"[\",\"]\",\"'\",'\"',\",\",\"`\"]])\n",
    "    word_tokens = word_tokenize(rm_punctuation)\n",
    "    clean_text = \" \".join(w for w in word_tokens if not w in stop_words)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi heera 85 lal man\n"
     ]
    }
   ],
   "source": [
    "print(text_cleaner(\".hi heera . [85] lal no do this. man !!!!!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(text_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>films adapted comic books plenty success wheth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>starters created alan moore eddie campbell bro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>say moore campbell thoroughly researched subje...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book graphic novel 500 pages long includes nea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>words nt dismiss film source</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  tag\n",
       "0  films adapted comic books plenty success wheth...    1\n",
       "1  starters created alan moore eddie campbell bro...    1\n",
       "2  say moore campbell thoroughly researched subje...    1\n",
       "3  book graphic novel 500 pages long includes nea...    1\n",
       "4                       words nt dismiss film source    1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        films adapted comic books plenty success wheth...\n",
       "1        starters created alan moore eddie campbell bro...\n",
       "2        say moore campbell thoroughly researched subje...\n",
       "3        book graphic novel 500 pages long includes nea...\n",
       "4                             words nt dismiss film source\n",
       "                               ...                        \n",
       "64715      lack inspiration traced back insipid characters\n",
       "64716    like many skits current incarnation _saturday_...\n",
       "64717    watching one roxbury skits snl come away chara...\n",
       "64718                              bump unsuspecting women\n",
       "64719       watching _a_night_at_the_roxbury_ left exactly\n",
       "Name: text, Length: 64720, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[\"text\"]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64720, 39679)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X = count_vect.fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "64715    0\n",
       "64716    0\n",
       "64717    0\n",
       "64718    0\n",
       "64719    0\n",
       "Name: tag, Length: 64720, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[\"tag\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7061186650185414\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy\",accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"this movie was a waste of time \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 23105)\t1\n",
      "  (0, 24394)\t1\n",
      "  (0, 35412)\t1\n",
      "  (0, 35627)\t1\n",
      "  (0, 38425)\t1\n",
      "  (0, 38437)\t1\n"
     ]
    }
   ],
   "source": [
    "review_vec = count_vect.transform([review])\n",
    "print(review_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = {1:\"Positive\",0:\"Negative\"}\n",
    "result[model.predict(review_vec)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'streamlit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-12b511d36365>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'"
     ]
    }
   ],
   "source": [
    "import streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-0.82.0-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.2 MB 9.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.21.0 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from streamlit) (1.0.5)\n",
      "Requirement already satisfied: python-dateutil in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from streamlit) (2.8.1)\n",
      "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from streamlit) (3.12.2)\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting blinker\n",
      "  Downloading blinker-1.4.tar.gz (111 kB)\n",
      "\u001b[K     |████████████████████████████████| 111 kB 24.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from streamlit) (1.18.5)\n",
      "Requirement already satisfied: tornado>=5.0 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from streamlit) (6.0.4)\n",
      "Collecting watchdog; platform_system != \"Darwin\"\n",
      "  Downloading watchdog-2.1.1-py3-none-manylinux2014_x86_64.whl (74 kB)\n",
      "\u001b[K     |████████████████████████████████| 74 kB 4.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting validators\n",
      "  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\n",
      "Collecting click<8.0,>=7.0\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Requirement already satisfied: requests in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from streamlit) (2.22.0)\n",
      "Collecting altair>=3.2.0\n",
      "  Downloading altair-4.1.0-py3-none-any.whl (727 kB)\n",
      "\u001b[K     |████████████████████████████████| 727 kB 18.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydeck>=0.1.dev5\n",
      "  Downloading pydeck-0.6.2-py2.py3-none-any.whl (4.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.2 MB 22.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: gitpython in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from streamlit) (3.1.3)\n",
      "Requirement already satisfied: cachetools>=4.0 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from streamlit) (4.1.1)\n",
      "Requirement already satisfied: packaging in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from streamlit) (20.4)\n",
      "Collecting tzlocal\n",
      "  Downloading tzlocal-2.1-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: astor in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from streamlit) (0.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from streamlit) (8.1.2)\n",
      "Collecting pyarrow; python_version < \"3.9\"\n",
      "  Downloading pyarrow-4.0.0-cp37-cp37m-manylinux2014_x86_64.whl (21.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.8 MB 16.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting base58\n",
      "  Downloading base58-2.1.0-py3-none-any.whl (5.6 kB)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from pandas>=0.21.0->streamlit) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from python-dateutil->streamlit) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from protobuf!=3.11,>=3.6.0->streamlit) (47.3.1.post20200616)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from validators->streamlit) (4.4.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from requests->streamlit) (1.25.9)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from requests->streamlit) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from requests->streamlit) (2020.4.5.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from requests->streamlit) (3.0.4)\n",
      "Requirement already satisfied: entrypoints in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from altair>=3.2.0->streamlit) (0.3)\n",
      "Requirement already satisfied: toolz in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from altair>=3.2.0->streamlit) (0.10.0)\n",
      "Requirement already satisfied: jsonschema in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from altair>=3.2.0->streamlit) (3.2.0)\n",
      "Requirement already satisfied: jinja2 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from altair>=3.2.0->streamlit) (2.11.2)\n",
      "Requirement already satisfied: traitlets>=4.3.2 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from pydeck>=0.1.dev5->streamlit) (4.3.3)\n",
      "Requirement already satisfied: ipykernel>=5.1.2; python_version >= \"3.4\" in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from pydeck>=0.1.dev5->streamlit) (5.3.0)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from pydeck>=0.1.dev5->streamlit) (7.5.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from gitpython->streamlit) (4.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from packaging->streamlit) (2.4.7)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from jsonschema->altair>=3.2.0->streamlit) (0.16.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from jsonschema->altair>=3.2.0->streamlit) (19.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from jsonschema->altair>=3.2.0->streamlit) (1.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from jinja2->altair>=3.2.0->streamlit) (1.1.1)\n",
      "Requirement already satisfied: ipython-genutils in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (7.12.0)\n",
      "Requirement already satisfied: jupyter-client in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (6.1.3)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.0.6)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->gitpython->streamlit) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema->altair>=3.2.0->streamlit) (3.1.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.17.1)\n",
      "Requirement already satisfied: backcall in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
      "Requirement already satisfied: pygments in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (2.6.1)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (3.0.5)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (4.6.3)\n",
      "Requirement already satisfied: pyzmq>=13 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (19.0.1)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (6.0.3)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ptyprocess>=0.5 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.2.4)\n",
      "Requirement already satisfied: nbconvert in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n",
      "Requirement already satisfied: prometheus-client in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.0)\n",
      "Requirement already satisfied: Send2Trash in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.3)\n",
      "Requirement already satisfied: testpath in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
      "Requirement already satisfied: bleach in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.1.5)\n",
      "Requirement already satisfied: defusedxml in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.6.0)\n",
      "Requirement already satisfied: webencodings in /home/heera/anaconda3/envs/tf2/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
      "Building wheels for collected packages: blinker\n",
      "  Building wheel for blinker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13452 sha256=ee6645ae8596bb9b0ba9989cb5e12d7883250a9a018b3c2e9079e6ed3d5c84c3\n",
      "  Stored in directory: /home/heera/.cache/pip/wheels/22/f5/18/df711b66eb25b21325c132757d4314db9ac5e8dabeaf196eab\n",
      "Successfully built blinker\n",
      "Installing collected packages: toml, blinker, watchdog, validators, click, altair, pydeck, tzlocal, pyarrow, base58, streamlit\n",
      "Successfully installed altair-4.1.0 base58-2.1.0 blinker-1.4 click-7.1.2 pyarrow-4.0.0 pydeck-0.6.2 streamlit-0.82.0 toml-0.10.2 tzlocal-2.1 validators-0.18.2 watchdog-2.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
